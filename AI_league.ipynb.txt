{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lama506/arabic-sign-language/blob/main/AI_league.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGBxYGN0O4Up",
        "outputId": "1926d8ed-dd0d-4148-ab42-8cb1784c84ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ± ÙˆÙ…Ù„Ù CSV Ø¨Ù†Ø¬Ø§Ø­!\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©\n",
        "image_path = \"/content/Screenshot 2025-04-08 184526.png\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©\n",
        "rows, cols = 5, 7\n",
        "\n",
        "# Ø­Ø¬Ù… ÙƒÙ„ Ø®Ø§Ù†Ø©\n",
        "cell_width = image.width // cols\n",
        "cell_height = image.height // rows\n",
        "\n",
        "arabic_letters = [\n",
        "    \"Ø®\", \"Ø­\", \"Ø¬\", \"Ø«\", \"Øª\", \"Ø¨\", \"Ø§\",\n",
        "    \"Øµ\", \"Ø´\", \"Ø³\", \"Ø²\", \"Ø±\", \"Ø°\", \"Ø¯\",\n",
        "    \"Ù‚\", \"Ù\", \"Øº\", \"Ø¹\", \"Ø¸\", \"Ø·\", \"Ø¶\",\n",
        "    \"ÙŠ\", \"Ùˆ\", \"Ù‡\", \"Ù†\", \"Ù…\", \"Ù„\", \"Ùƒ\",\n",
        "    \"Ø¢\", \"Ø¥\", \"Ø£\", \"Ø¤\", \"Ø¦\", \"Ø¡\", \"Ù„Ø§\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Ø¹ÙƒØ³ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±\n",
        "#arabic_letters.reverse()\n",
        "\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ù‚ØµÙˆØµØ©\n",
        "output_dir = \"letters\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Ø¨ÙŠØ§Ù†Ø§Øª CSV\n",
        "csv_data = [(\"image_filename\", \"letter\")]\n",
        "\n",
        "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø©\n",
        "counter = 0\n",
        "for row in range(rows):\n",
        "    for col in range(cols):\n",
        "        left = col * cell_width\n",
        "        upper = row * cell_height\n",
        "        right = left + cell_width\n",
        "        lower = upper + cell_height\n",
        "        cropped = image.crop((left, upper, right, lower)).convert(\"RGB\")\n",
        "        letter = arabic_letters[counter]\n",
        "        filename = f\"{letter}.jpg\"\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "        cropped.save(filepath)\n",
        "        csv_data.append((filename, letter))\n",
        "        counter += 1\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù CSV\n",
        "with open(\"arabic_sign_language.csv\", mode=\"w\", newline='', encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(csv_data)\n",
        "\n",
        "print(\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ± ÙˆÙ…Ù„Ù CSV Ø¨Ù†Ø¬Ø§Ø­!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª\n",
        "!pip install -q openai-whisper ffmpeg-python genai\n",
        "\n",
        "# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "import whisper\n",
        "import os\n",
        "import datetime\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmlS1EI8O5Nv",
        "outputId": "2d04cbfb-0c8a-4e9e-e9ec-dd965e90a984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m830.9/830.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.35.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y genai\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxPaeUMjTptL",
        "outputId": "8c9e60a7-6056-47f1-dd75-8eed0ebc084e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping genai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 3. ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# âœ… 4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ Ù†Øµ\n",
        "video_path = \"/content/Screen Recording 2025-04-08 023046.mp4\"\n",
        "result = model.transcribe(video_path, language=\"ar\")\n",
        "arabic_text = result['text']\n",
        "print(\"ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:\", arabic_text)\n",
        "\n",
        "# âœ… Ø¥Ø¹Ø¯Ø§Ø¯ Gemini\n",
        "genai.configure(api_key=\"AIzaSyD6m88SOk3u-BufsNRr8LVyMfPuROH6KYM\")\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
        "\n",
        "# âœ… 5. Ø¯ÙˆØ§Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ ÙˆØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ\n",
        "def replace_arabic_letters(text):\n",
        "    replacements = {\n",
        "        \"Ø£\": \"Ø§\",\n",
        "        \"Ø¥\": \"Ø§\",\n",
        "        \"Ø¢\": \"Ø§\",\n",
        "        \"Ø©\": \"Ù‡\",\n",
        "        \"Ù‰\": \"ÙŠ\",\n",
        "        \"Ø¦\": \"ÙŠ\",\n",
        "        \"Ø¤\": \"Ùˆ\",\n",
        "    }\n",
        "    for src, target in replacements.items():\n",
        "        text = text.replace(src, target)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„\n",
        "    text = re.sub(r'[\\u064B-\\u065F]', '', text)\n",
        "    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©\n",
        "def extract_keywords_gemini(text):\n",
        "    processed_text = replace_arabic_letters(clean_text(text))\n",
        "    prompt = f\"Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­:\\n{processed_text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    result = response.text\n",
        "    raw_keywords = [k.strip() for k in result.replace(\"ØŒ\", \",\").split(\",\") if k.strip()]\n",
        "    keywords = [replace_arabic_letters(clean_text(k)) for k in raw_keywords]\n",
        "    print(f\"ğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Gemini): {keywords}\")\n",
        "    return keywords\n",
        "\n",
        "# âœ… 6. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ù‰ ØµÙˆØ± Ø­Ø±ÙˆÙ\n",
        "def make_sign_sequence_from_text(text, letters_path=\"/content/letters\"):\n",
        "    images = []\n",
        "    for word in text.split():\n",
        "        # ÙŠÙ…ÙƒÙ†Ùƒ Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø© ÙƒØµÙˆØ±Ø© Ù‡Ù†Ø§ Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ ØµÙˆØ±Ø© Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©\n",
        "        for letter in word:\n",
        "            img_path = os.path.join(letters_path, f\"{letter}.jpg\")\n",
        "            if os.path.exists(img_path):\n",
        "                images.append(Image.open(img_path))\n",
        "            else:\n",
        "                print(f\"âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù„Ù„Ø­Ø±Ù: {letter}\")\n",
        "    return images\n",
        "\n",
        "# âœ… 7. Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ\n",
        "def save_images_as_video(images, output_path=\"output_video.mp4\", fps=1):\n",
        "    if not images:\n",
        "        print(\"âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±\")\n",
        "        return\n",
        "\n",
        "    width, height = images[0].size\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for img in images:\n",
        "        img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "        video.write(img_np)\n",
        "\n",
        "    video.release()\n",
        "    print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {output_path}\")\n",
        "\n",
        "# âœ… 8. ØªÙ†ÙÙŠØ° ÙƒØ§Ù…Ù„ Ø§Ù„ØªØ³Ù„Ø³Ù„\n",
        "keywords = extract_keywords_gemini(arabic_text)\n",
        "all_images = []\n",
        "for word in keywords:\n",
        "    all_images.extend(make_sign_sequence_from_text(word))\n",
        "\n",
        "save_images_as_video(all_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "U_htVX0CTi47",
        "outputId": "faf0230a-d86f-448a-a6e0-48a5a468bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:  ØªØ§ÙˆØª Ø§Ù„ÙƒØ±Ø§Ù…Ø±Ø© Ù†Ø®Ø±Ù‰ Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ÙŠÙ† Ù…ØªØ§Ø¨Ø¹ÙŠÙ† ÙŠØ¬ØªÙ…Ø¹ ÙÙŠÙ‡ ÙƒÙ„Ù‡ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¥Ø«Ø§Ø±Ø© ÙˆØ§Ù„Ù…ØªØ¹Ø¨ ÙƒÙ„Ù…Ø§ Ù†ØªØ¸Ø±Ø© ÙÙ‚Ø· Ø¨Ø¯Ø§ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø¨ÙŠ Ø§Ù‡Ø¯Ø§ÙÙ‡ Ù„Ù‚ØªØ§ØªÙ‡ ÙØ±ØµÙ‡ Ø¬Ù…Ø§Ù„ÙŠØ§Øª Ù…Ù‡Ø§Ø±Ø§ØªØ© Ù„Ø§Ø­Ø¯\n",
            "ğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Gemini): ['Ù„Ù‚Ø§Ø¡', 'Ù…Ø´Ø§Ù‡Ø¯Ù‡', 'Ø§Ø«Ø§Ø±Ù‡', 'Ù…ØªØ¹Ù‡', 'Ø¯Ø±Ø¨', 'Ø§Ù‡Ø¯Ø§Ù', 'Ù„Ø­Ø¸Ø§Øª', 'ÙØ±Øµ', 'Ø¬Ù…Ø§Ù„ÙŠØ§Øª', 'Ù…Ù‡Ø§Ø±Ø§Øª']\n",
            "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: output_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 9. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Advanced Evaluation)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù†ÙØ³Ù‡\n",
        "def normalize_arabic(word):\n",
        "    return replace_arabic_letters(word)\n",
        "\n",
        "# Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹\n",
        "expected_keywords= keywords\n",
        "expected_letters = []\n",
        "for word in expected_keywords:\n",
        "    word = normalize_arabic(word)\n",
        "    expected_letters.extend(list(word))\n",
        "\n",
        "# Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ØªÙŠ Ø¸Ù‡Ø±Øª ÙØ¹Ù„ÙŠØ§Ù‹\n",
        "predicted_letters = [os.path.basename(img.filename).replace('.jpg', '') for img in all_images]\n",
        "\n",
        "# Ù‚Øµ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ù„Ø£Ù‚ØµØ± Ø·ÙˆÙ„ Ø­ØªÙ‰ Ù†Ù‚Ø¯Ø± Ù†Ø­Ø³Ø¨ metrics Ø­Ø±Ù Ø¨Ø­Ø±Ù\n",
        "min_len = min(len(expected_letters), len(predicted_letters))\n",
        "y_true = expected_letters[:min_len]\n",
        "y_pred = predicted_letters[:min_len]\n",
        "\n",
        "# Precision, Recall, F1 (Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø±Ù)\n",
        "precision = precision_score(y_true, y_pred, average='micro')\n",
        "recall = recall_score(y_true, y_pred, average='micro')\n",
        "f1 = f1_score(y_true, y_pred, average='micro')\n",
        "\n",
        "print(f\"ğŸ“Œ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {min_len}\")\n",
        "print(f\"âœ… Precision: {precision * 100:.2f}%\")\n",
        "print(f\"âœ… Recall:    {recall * 100:.2f}%\")\n",
        "print(f\"âœ… F1 Score:  {f1 * 100:.2f}%\")\n",
        "\n",
        "# âœ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØºØ·ÙŠØ© Coverage\n",
        "total_letters = sum(len(normalize_arabic(word)) for word in expected_keywords)\n",
        "covered_letters = len(predicted_letters)\n",
        "coverage = covered_letters / total_letters * 100\n",
        "print(f\"\\nğŸ“¦ ØªØºØ·ÙŠØ© Ø§Ù„ØµÙˆØ± (coverage): {coverage:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4hX7N0zZaBg",
        "outputId": "70db70ab-fa5f-4427-c621-6128fcc5175d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Œ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: 48\n",
            "âœ… Precision: 100.00%\n",
            "âœ… Recall:    100.00%\n",
            "âœ… F1 Score:  100.00%\n",
            "\n",
            "ğŸ“¦ ØªØºØ·ÙŠØ© Ø§Ù„ØµÙˆØ± (coverage): 100.00%\n"
          ]
        }
      ]
    }
  ]
}